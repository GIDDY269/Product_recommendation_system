{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA INGESTION NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1732887267906
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-30 20:56:05,355 ] 161 numexpr.utils - INFO - NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/azureuser/cloudfiles/code/Users/oviemunooboro/Product_recommendation_system')\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from src.utils.commons import read_yaml,create_directories\n",
    "from src.cloud_storage.azure_blob_storage import AzureDatastore\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from src.logger import logging\n",
    "import pandas  as pd\n",
    "from src.constants import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "from src.utils.commons import unzip_files\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1732887278115
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir : Path\n",
    "    local_path : Path\n",
    "    target_path : str\n",
    "    registered_name : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1732887291096
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        '''\n",
    "        Initiating the configuration manager\n",
    "        '''\n",
    "        # read YAML configuration files to initatiate configuration parameters\n",
    "        self.config = read_yaml(str(config_filepath))\n",
    "        self.params = read_yaml(str(params_filepath))\n",
    "        self.schema = read_yaml(str(schema_filepath))\n",
    "\n",
    "        logging.info(f'configuration: {self.config}')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    #configuration manager\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        '''\n",
    "        Function to get configuration settings\n",
    "        '''\n",
    "\n",
    "        # read data ingestion configuration section from config.yaml\n",
    "        config = self.config.DATA_INGESTION\n",
    "\n",
    "        # create a new artifacts folder to store ingested data if doesn't exist already \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # create and return dataingestion configuration object\n",
    "\n",
    "        config_object = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            local_path= config.local_path,\n",
    "            target_path=config.target_path,\n",
    "            registered_name= config.registered_name\n",
    "        )\n",
    "\n",
    "        return config_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1732887300975
    }
   },
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self,config:DataIngestionConfig):\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "    def initiate_data_ingestion(self):\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_timestamp = datetime.now().strftime(\"%m_%d_%Y %H:%M:%S\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            logging.info(f'Unziping file from {self.config.local_path} into {self.config.root_dir} ')\n",
    "            unzip_folder = os.path.join(self.config.root_dir,'ingested_data') # folder to extract data to\n",
    "\n",
    "            if not os.path.exists(unzip_folder) or not os.listdir(unzip_folder) :\n",
    "                unzip_files(self.config.local_path,unzip_folder)\n",
    "                logging.info(f'Data from {self.config.local_path} unzippeded into {unzip_folder}')\n",
    "            else:\n",
    "                logging.info(f'data from {self.config.local_path} already unzipped')\n",
    "                pass\n",
    "\n",
    "\n",
    "            Azure_ws = AzureDatastore()\n",
    "\n",
    "            Azure_ws.load_local_data_to_Azure_datastore(\n",
    "                src_dir = unzip_folder,\n",
    "                target_path = self.config.target_path,\n",
    "                registered_name = self.config.registered_name\n",
    "            )\n",
    "\n",
    "            number_of_files = len(os.listdir(unzip_folder))\n",
    "            logging.info(f'Number of ingested files : {number_of_files}')\n",
    "\n",
    "\n",
    "            # save metadata\n",
    "            end_time = time.time()\n",
    "            end_timestamp = datetime.now().strftime(\"%m_%d_%Y %H:%M:%S\")\n",
    "            duration = end_time - start_time\n",
    "            metadata = {\n",
    "                'start_time' : start_timestamp,\n",
    "                'end_time' : end_timestamp,\n",
    "                'duration' : duration,\n",
    "                'Number of files loaded to workspace' : number_of_files,\n",
    "                'data_source' : self.config.local_path,\n",
    "                'target_path_from_datastore' : self.config.target_path,\n",
    "                'registered_name' : self.config.registered_name,\n",
    "                'Project name' : 'Data ingestion'\n",
    "            }\n",
    "            metadata_path = os.path.join(unzip_folder,'metadata.json')\n",
    "            pd.Series(metadata).to_json(metadata_path)\n",
    "    \n",
    "            logging.info(f'saved ingestion pipeline metadata into {metadata_path}')\n",
    "            \n",
    "        except ClientError as e:             \n",
    "            logging.info(f'error occured {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1732887778038
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-30 21:05:50,895 ] 38 root - INFO - Yaml file:  config/config.yaml loaded suscessfully\n",
      "[2024-11-30 21:05:50,924 ] 38 root - INFO - Yaml file:  params.yaml loaded suscessfully\n",
      "[2024-11-30 21:05:50,942 ] 38 root - INFO - Yaml file:  schema.yaml loaded suscessfully\n",
      "[2024-11-30 21:05:50,943 ] 13 root - INFO - configuration: {'DATA_INGESTION': {'root_dir': 'Artifacts', 'local_path': '/home/azureuser/cloudfiles/code/Users/oviemunooboro/Product_recommendation_system/Artifacts/customer_interactions.zip', 'target_path': 'Artifacts/Ingested_data', 'registered_name': 'customer_interaction_dataset', 'bucket_name': 'cosmetic-store', 'filename': 'Artifacts/Ingested_data.zip', 'object_name': 'archive (1).zip'}, 'DATA_VALIDATION': {'root_dir': 'Artifacts/data_validation', 'data_source': 'Artifacts/Raw_ingested_data/', 'status_file': 'Artifacts/data_validation/status.json', 'critical_columns': ['event_time', 'event_type', 'product_id', 'category_id', 'category_code', 'brand', 'price', 'user_id', 'user_session']}}\n",
      "[2024-11-30 21:05:50,948 ] 61 root - INFO - File directory create at : Artifacts\n",
      "[2024-11-30 21:05:50,949 ] 13 root - INFO - Unziping file from /home/azureuser/cloudfiles/code/Users/oviemunooboro/Product_recommendation_system/Artifacts/customer_interactions.zip into Artifacts \n",
      "[2024-11-30 21:05:50,967 ] 20 root - INFO - data from /home/azureuser/cloudfiles/code/Users/oviemunooboro/Product_recommendation_system/Artifacts/customer_interactions.zip already unzipped\n",
      "[2024-11-30 21:05:50,968 ] 16 root - INFO - configuring workspace\n",
      "[2024-11-30 21:05:51,040 ] 291 azureml.core.workspace - INFO - Found the config file in: /config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-30 21:05:51,562 ] 991 azureml.data.datastore_client - INFO - <azureml.core.authentication.InteractiveLoginAuthentication object at 0x7f0d28e37cd0>\n",
      "[2024-11-30 21:05:53,291 ] 53 root - INFO - Uploading data from local machine into blob storage using datastore\n",
      "[2024-11-30 21:05:53,292 ] 923 azureml.data.azure_storage_datastore - INFO - Called AzureBlobDatastore.upload\n",
      "Uploading an estimated of 6 files\n",
      "[2024-11-30 21:05:53,565 ] 372 azureml.data.azure_storage_datastore - INFO - Uploading an estimated of 6 files\n",
      "Uploading Artifacts/ingested_data/metadata.json\n",
      "[2024-11-30 21:05:53,821 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/metadata.json - INFO - Uploading Artifacts/ingested_data/metadata.json\n",
      "Uploaded Artifacts/ingested_data/metadata.json, 1 files out of an estimated total of 6\n",
      "[2024-11-30 21:05:53,824 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/metadata.json - INFO - Uploaded Artifacts/ingested_data/metadata.json, 1 files out of an estimated total of 6\n",
      "Uploading Artifacts/ingested_data/2019-Dec.csv\n",
      "[2024-11-30 21:06:09,603 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Dec.csv - INFO - Uploading Artifacts/ingested_data/2019-Dec.csv\n",
      "Uploaded Artifacts/ingested_data/2019-Dec.csv, 2 files out of an estimated total of 6\n",
      "[2024-11-30 21:06:09,604 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Dec.csv - INFO - Uploaded Artifacts/ingested_data/2019-Dec.csv, 2 files out of an estimated total of 6\n",
      "Uploading Artifacts/ingested_data/2020-Jan.csv\n",
      "[2024-11-30 21:06:12,614 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2020-Jan.csv - INFO - Uploading Artifacts/ingested_data/2020-Jan.csv\n",
      "Uploaded Artifacts/ingested_data/2020-Jan.csv, 3 files out of an estimated total of 6\n",
      "[2024-11-30 21:06:12,615 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2020-Jan.csv - INFO - Uploaded Artifacts/ingested_data/2020-Jan.csv, 3 files out of an estimated total of 6\n",
      "Uploading Artifacts/ingested_data/2019-Oct.csv\n",
      "[2024-11-30 21:06:12,868 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Oct.csv - INFO - Uploading Artifacts/ingested_data/2019-Oct.csv\n",
      "Uploaded Artifacts/ingested_data/2019-Oct.csv, 4 files out of an estimated total of 6\n",
      "[2024-11-30 21:06:12,870 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Oct.csv - INFO - Uploaded Artifacts/ingested_data/2019-Oct.csv, 4 files out of an estimated total of 6\n",
      "Uploading Artifacts/ingested_data/2020-Feb.csv\n",
      "[2024-11-30 21:06:12,872 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2020-Feb.csv - INFO - Uploading Artifacts/ingested_data/2020-Feb.csv\n",
      "Uploaded Artifacts/ingested_data/2020-Feb.csv, 5 files out of an estimated total of 6\n",
      "[2024-11-30 21:06:12,873 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2020-Feb.csv - INFO - Uploaded Artifacts/ingested_data/2020-Feb.csv, 5 files out of an estimated total of 6\n",
      "Uploading Artifacts/ingested_data/2019-Nov.csv\n",
      "[2024-11-30 21:06:14,627 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Nov.csv - INFO - Uploading Artifacts/ingested_data/2019-Nov.csv\n",
      "Uploaded Artifacts/ingested_data/2019-Nov.csv, 6 files out of an estimated total of 6\n",
      "[2024-11-30 21:06:14,629 ] 372 azureml.data.azure_storage_datastore.task_upload_Artifacts/Ingested_data/2019-Nov.csv - INFO - Uploaded Artifacts/ingested_data/2019-Nov.csv, 6 files out of an estimated total of 6\n",
      "Uploaded 6 files\n",
      "[2024-11-30 21:06:14,631 ] 372 azureml.data.azure_storage_datastore - INFO - Uploaded 6 files\n",
      "[2024-11-30 21:06:14,632 ] 941 azureml.data.azure_storage_datastore - INFO - Finished AzureBlobDatastore.upload with count=6.\n",
      "[2024-11-30 21:06:14,634 ] 60 root - INFO - Files uploaded into blob store sucessesfully\n",
      "[2024-11-30 21:06:14,635 ] 64 root - INFO - Registering dataset into workspace\n",
      "[2024-11-30 21:06:14,636 ] 68 root - INFO - File path for dataset: Artifacts/Ingested_data/*.csv\n",
      "[2024-11-30 21:06:14,703 ] 71 root - INFO - Registering dataset with name: customer_interaction_dataset\n",
      "[2024-11-30 21:06:16,840 ] 77 root - INFO - Dataset customer_interaction_dataset is registered successfully.\n",
      "[2024-11-30 21:06:16,863 ] 33 root - INFO - Number of ingested files : 6\n",
      "[2024-11-30 21:06:16,911 ] 32 root - INFO - Adding metadata (tags) to datastore\n",
      "[2024-11-30 21:06:16,913 ] 36 root - ERROR - Error occurred while adding metadata: 'AzureBlobDatastore' object has no attribute 'add_tags'\n",
      "[2024-11-30 21:06:16,915 ] 54 root - INFO - saved ingestion pipeline metadata into Artifacts/ingested_data/metadata.json\n"
     ]
    }
   ],
   "source": [
    "manager = ConfigurationManager()\n",
    "data_ingestion_config = manager.get_data_ingestion_config()\n",
    "\n",
    "\n",
    "data = DataIngestion(config=data_ingestion_config)\n",
    "filepath = data.initiate_data_ingestion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
